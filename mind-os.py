import sys
import argparse
import pandas as pd
from scripts.consistency_check import scan_system
from scripts.radar_gen import create_radar_chart
from scripts.memory_engine import sync_memory, query_memory, semantic_route

def main():
    parser = argparse.ArgumentParser(description="Mind-OS CLI - Your Psyche's Management Tool")
    subparsers = parser.add_subparsers(dest="command", help="Available commands")

    # Audit command
    subparsers.add_parser("audit", help="Scan system for logical gaps and metadata issues")

    # Viz command
    subparsers.add_parser("viz", help="Generate 5D Ability Radar chart")
    
    # UI/Dashboard command
    subparsers.add_parser("ui", help="Launch the real-time Visual Dashboard")

    # Memory Sync command
    subparsers.add_parser("sync", help="Sync local notes into semantic memory (LlamaIndex)")

    # Query command
    query_parser = subparsers.add_parser("query", help="Query semantic memory")
    query_parser.add_argument("text", type=str, help="The query text")
    
    # Report command
    subparsers.add_parser("report", help="Generate a narrative AI synthesis of your current growth state")

    # Capture command
    capture_parser = subparsers.add_parser("capture", help="Quickly log a thought or insight")
    capture_parser.add_argument("message", type=str, help="The thought to record")
    
    # Set command
    set_parser = subparsers.add_parser("set", help="Quickly update a score and log evidence")
    set_parser.add_argument("dimension", type=str, help="The dimension to update (e.g., æ‰§è¡ŒåŠ›)")
    set_parser.add_argument("score", type=int, help="The new score (0-100)")
    set_parser.add_argument("evidence", type=str, help="The evidence or reason for change")

    args = parser.parse_args()

    if args.command == "audit":
        scan_system(".")
    elif args.command == "viz":
        create_radar_chart()
    elif args.command == "ui":
        import subprocess
        print("ğŸŒ Launching Mind-OS Dashboard...")
        subprocess.run([sys.executable, "-m", "streamlit", "run", "scripts/dashboard.py"])
    elif args.command == "sync":
        sync_memory()
    elif args.command == "query":
        query_memory(args.text)
    elif args.command == "report":
        generate_narrative_report()
    elif args.command == "capture":
        semantic_route(args.message)
    elif args.command == "set":
        update_stat(args.dimension, args.score, args.evidence)
    else:
        parser.print_help()

def update_stat(dimension, score, evidence):
    """Update a specific dimension score and append evidence."""
    import os
    import re
    import datetime
    
    print(f"âš¡ Updating {dimension} to {score}...")
    
    # Mapping table to internal YAML keys
    key_map = {
        "è®¤çŸ¥åŠ›": "cognitive_score",
        "æ‰§è¡ŒåŠ›": "execution_score",
        "æƒ…æ„ŸåŠ›": "emotional_score",
        "ç¤¾äº¤åŠ›": "social_score",
        "åˆ›é€ åŠ›": "creativity_score"
    }
    
    if dimension not in key_map:
        print(f"âŒ Error: Unknown dimension '{dimension}'. Please use one of: {list(key_map.keys())}")
        return

    # For now, we update the master file: çŸ¥è¯†ç”»åƒ/ç»¼åˆç”»åƒ.md
    target_file = "çŸ¥è¯†ç”»åƒ/ç»¼åˆç”»åƒ.md"
    if not os.path.exists(target_file):
        print(f"âŒ Error: {target_file} not found.")
        return

    with open(target_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # 1. Update YAML score
    yaml_key = key_map[dimension]
    pattern = rf"({yaml_key}:\s*)\d+"
    if re.search(pattern, content):
        new_content = re.sub(pattern, rf"\g<1>{score}", content)
    else:
        # If key not found, insert it before 'last_updated' or at the end of frontmatter
        if "---" in content:
            parts = content.split("---", 2)
            if len(parts) >= 3:
                parts[1] = parts[1].strip() + f"\n{yaml_key}: {score}\n"
                new_content = "---" + parts[1] + "---" + parts[2]
            else:
                new_content = content + f"\n{yaml_key}: {score}"
        else:
            new_content = content + f"\n{yaml_key}: {score}"
    
    # 2. Append Evidence
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
    evidence_block = f"\n\n### ğŸ“ˆ {dimension} å˜åŠ¨è®°å½• ({timestamp})\n"
    evidence_block += f"- **æ–°åˆ†å€¼**: {score}\n"
    evidence_block += f"- **åŸå› /è¯æ®**: {evidence}\n"
    
    new_content += evidence_block
    
    with open(target_file, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print(f"âœ… {target_file} updated. Re-generating radar chart...")
    from scripts.radar_gen import create_radar_chart
    create_radar_chart()

def generate_narrative_report():
    """Synthesize a deep AI narrative report based on semantic memory."""
    import datetime
    import os
    from scripts.radar_gen import get_dynamic_scores, load_config
    
    print("ğŸ“œ Generating Deep AI Growth Report...")
    config = load_config()
    scores = get_dynamic_scores(config)
    dims = [d.get('key', d['name']) for d in config.get('radar', {}).get('dimensions', [])]
    score_dict = dict(zip(dims, scores))
    
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d")
    
    report = f"""# ğŸ§  Mind-OS æ·±åº¦å®¡è®¡æŠ¥å‘Š ({timestamp})

## 1. ğŸ“Š ç°çŠ¶å¿«ç…§
{pd.DataFrame([score_dict]).T.to_markdown()}

## 2. ğŸ” æ ¸å¿ƒæ´å¯Ÿ (Semantic Synthesis)
"""
    # Use retrieval to find recent "captured thoughts" to synthesize themes
    from scripts.memory_engine import query_memory
    recent_thoughts = query_memory("è¿‘æœŸå‘ç°çš„æ½œæ„è¯†æ¨¡å¼ä¸æ‰§è¡Œç“¶é¢ˆ")
    
    if recent_thoughts:
        report += "\n### ğŸ§Š æ½œæ„è¯†å†°å±±ä¹‹ä¸‹\n"
        for i, node in enumerate(recent_thoughts[:3]):
            report += f"- **æ ¸å¿ƒç‰‡æ®µ {i+1}**: {node.text[:150]}... (æ¥æº: {os.path.basename(node.metadata.get('file_path'))})\n"
    
    report += "\n## 3. âš–ï¸ ä¸–ç•Œè§‚å†²çªæ£€æŸ¥ (Worldview Audit)\n"
    
    # WORLDVIEW CONFLICT LOGIC
    # Hypothesis: Search for contradictions between 'Finance' (Logic/Asset) and 'Awareness' (Internal)
    conflicts = query_memory("å†²çªã€çŸ›ç›¾ã€çŸ¥è¡Œä¸ä¸€ã€é˜²å¾¡æœºåˆ¶")
    if conflicts:
        report += "> [!WARNING]\n"
        report += "> æ£€æµ‹åˆ°ä»¥ä¸‹æ·±å±‚è¯­ä¹‰å†²çªï¼š\n"
        for c in conflicts[:2]:
            report += f"> - **æ½œåœ¨çº¿ç´¢**: {c.text[:200]}...\n"

    report += "\n## 4. ğŸš€ ä¼˜å…ˆçº§è¡ŒåŠ¨å»ºè®®\n"
    if score_dict.get('æ‰§è¡ŒåŠ›', 0) > score_dict.get('è®¤çŸ¥åŠ›', 0) + 10:
        report += "- **åœæ­¢ç›²ç›®è¡ŒåŠ¨**ï¼šæ‚¨çš„æ‰§è¡ŒåŠ›è¿œè¶…è®¤çŸ¥ï¼Œå»ºè®®å›æµè‡³å°‘ 10 å°æ—¶è¿›å…¥ã€Šæ€ç»´æ¨¡å‹ã€‹ç»ƒä¹ ï¼Œé˜²æ­¢æ–¹å‘æ€§åèˆªã€‚\n"
    if score_dict.get('ç¤¾äº¤åŠ›', 0) < 30:
        report += "- **æ¿€æ´»å¤–éƒ¨é“¾æ¥**ï¼šç¤¾äº¤åˆ†å€¼è¿‡ä½ã€‚å°è¯•å°†æœ¬å‘¨çš„ä¸€ä¸ªè®¤çŸ¥éš¾é¢˜ä¸»åŠ¨åˆ†äº«ç»™ä¸€ä½åœ¨è¯¥é¢†åŸŸæœ‰å»ºæ ‘çš„æœ‹å‹ï¼Œæ‰“ç ´å­¤ç‹¼é—­ç¯ã€‚\n"

    report_path = "åˆ†ææŠ¥å‘Š/AIæ·±åº¦å®¡è®¡æŠ¥å‘Š.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
        
    print(f"âœ… Report generated: {report_path}")
    print("---------------------------------")
    print(report)
    print("---------------------------------")

if __name__ == "__main__":
    main()
